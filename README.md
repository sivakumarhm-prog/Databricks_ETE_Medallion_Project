# ðŸš€ ETE Databricks Medallion Project

## ðŸ”¹ Overview
End-to-end data engineering project implemented on **Databricks** using **ADLS Gen2, Unity Catalog, Autoloader, and Delta Live Tables**.  
The goal was to build a **medallion architecture (Bronze â†’ Silver â†’ Gold)** enforcing **star schema** at the gold layer.

---

## ðŸ”¹ Data Sources
Input files placed by source team into **ADLS Gen2 `source` container**:

- `region/` â†’ Lookup dataset (one-time load)  
- `customers/` â†’ Dimension table (**SCD Type 1**)  
- `products/` â†’ Dimension table (**SCD Type 2 with DLT**)  
- `orders/` â†’ Fact table  

---

## ðŸ”¹ Architecture

### Bronze Layer
- **Region dataset** â†’ Ingested via **Databricks data ingestion UI** (no code).  
- **Customers, Products, Orders** â†’ Ingested via **Autoloader** (structured streaming with checkpointing).  
- All tables registered under **Unity Catalog**.  

### Silver Layer
- Transformations applied to **clean, standardize, and join** datasets.  
- Stored as **Delta tables** in the Silver schema.  

### Gold Layer
- **Customers** â†’ Implemented **SCD Type 1** (overwrite updates).  
- **Products** â†’ Implemented **SCD Type 2** (historical tracking using Delta Live Tables).  
- **Orders** â†’ Fact table, joined with dimensions.  
- Final schema enforces **star schema** for analytics.  

---

## ðŸ”¹ Tech Stack
- Databricks
- Metastore Creation and Workspace assignment.
- Access Connector for Azure Databricks.
- AutoLoader capabilities of Spark Structured Streaming.
- Basic and Advanced PySpark functions.
- Azure Data Lake Storage Gen2 (ADLS Gen2)  
- Delta Lake (Bronze / Silver / Gold layers)
- SCD - Type 1 and SCD - Type 2 using DLT

---

## ðŸ”¹ Project Flow Diagram
Example:
```bash
/docs/architecture.png
